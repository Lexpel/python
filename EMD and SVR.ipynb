{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fd2b8-5aed-40ac-9d24-aafb9d1cfff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db913c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trends is  27\n",
      "All variable EMD Analysis success\n",
      "SVR modeling success\n",
      "SVR smoothed aggregated success\n",
      "Final SVR smoothed residual success\n",
      "All data output now created in one file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyEMD import EMD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pylab as pylab\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as sm\n",
    "import warnings\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Set plot parameters\n",
    "params = {\n",
    "    'legend.fontsize': 'x-large',\n",
    "    'figure.figsize': (15, 5),\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'xtick.labelsize': 'xx-large',\n",
    "    'ytick.labelsize': 'xx-large'\n",
    "}\n",
    "pylab.rcParams.update(params)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# emd File paths\n",
    "abs_path = \"C:/Users/Owner/Documents/My_courses/Fall2023/Co-opAnalysis/variables/wetland/\"\n",
    "emd_file_name = \"Reformatted_Data_wetland\"\n",
    "emd_file_path = abs_path + emd_file_name + '.csv'\n",
    "\n",
    "# Modify CODE 1: EMD and Saving Results\n",
    "\n",
    "# Read original data\n",
    "original_data = pd.read_csv(filepath_or_buffer=emd_file_path, index_col='TimeID', parse_dates=True)\n",
    "counties = np.array(original_data.columns)\n",
    "\n",
    "residual = {}\n",
    "for county in counties:\n",
    "    x = np.array(original_data.index)\n",
    "    y = np.array(original_data[county])\n",
    "    \n",
    "    # Filter out rows with excessive zeros (adjust the threshold as needed)\n",
    "    zero_threshold = 5  # Set the threshold for considering a row as excessive zeros\n",
    "    if np.count_nonzero(y) >= zero_threshold:\n",
    "        size = len(x)\n",
    "\n",
    "        # Execute EMD on signal\n",
    "        IMF = EMD().emd(y, x)\n",
    "\n",
    "        N = IMF.shape[0] + 1\n",
    "        temp = []\n",
    "\n",
    "        for n, imf in enumerate(IMF):\n",
    "            # Get current Residual(Trend) in current IMF\n",
    "            if n == (len(IMF) - 1):\n",
    "                temp = imf.tolist()\n",
    "\n",
    "        residual[county] = temp\n",
    "\n",
    "print(\"The number of trends is \", len(residual))\n",
    "\n",
    "df3 = DataFrame(residual)\n",
    "df3.to_csv(abs_path + 'All_EMD_Residuals.csv', index=False)\n",
    "\n",
    "# Rest of your code (CODE 2 and CODE 3) remains unchanged.\n",
    "\n",
    "IMFs = {}\n",
    "for county in counties:\n",
    "    x = np.array(original_data.index)\n",
    "    y = np.array(original_data[county])\n",
    "\n",
    "    # Execute EMD on signal\n",
    "    IMF = EMD().emd(y, x)\n",
    "    for n, imf in enumerate(IMF):\n",
    "        temp = imf.tolist()\n",
    "        temp.append(county)\n",
    "        temp.append(n+1)\n",
    "        IMFs['IMF_' + county + '_' + str(n+1)] = temp\n",
    "        \n",
    "df = DataFrame(IMFs)\n",
    "df.to_csv(abs_path + 'All_EMD_IMFs.csv', index=False)\n",
    "\n",
    "print('All variable EMD Analysis success')\n",
    "\n",
    "# CODE 2: SVR Modeling\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "# Read the input file\n",
    "svr_file_name = pd.read_csv(abs_path + \"All_EMD_IMFs.csv\")\n",
    "original_data = svr_file_name\n",
    "IMFs = original_data.columns\n",
    "\n",
    "for imf in IMFs:\n",
    "    x_in = np.arange(0, 18)\n",
    "    X = np.array(x_in.reshape(18, 1))\n",
    "    scaler_X = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "    cur_data = np.array(original_data[imf].tolist())\n",
    "    y = np.array(cur_data[:18])\n",
    "\n",
    "    cur_countyIndex = str(int(cur_data[18]))\n",
    "    cur_IMFIndex = str(int(cur_data[19]))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Y_scaled = scaler.fit_transform(y.reshape((18, 1)))\n",
    "\n",
    "    y = Y_scaled.flatten()\n",
    "    X = X_scaled\n",
    "\n",
    "    C_list = np.append(np.arange(1.001, 10, 1), 100)\n",
    "    gamma_list = np.append(np.arange(1.001, 10, 1), 100)\n",
    "\n",
    "    grid = GridSearchCV(SVR(kernel='rbf'), param_grid={\"C\": C_list, \"gamma\": gamma_list}, cv=4, scoring='explained_variance')\n",
    "    grid.fit(X, y)\n",
    "    b1 = grid.best_params_['C']\n",
    "    g1 = grid.best_params_['gamma']\n",
    "\n",
    "    C_list2 = np.arange(b1 - 1, b1 + 1, 0.1)\n",
    "    gamma_list2 = np.arange(g1 - 1, g1 + 1, 0.1)\n",
    "\n",
    "    grid = GridSearchCV(SVR(kernel='rbf'), param_grid={\"C\": C_list2, \"gamma\": gamma_list2}, cv=4, scoring='explained_variance')\n",
    "    grid.fit(X, y)\n",
    "    b2 = grid.best_params_['C']\n",
    "    g2 = grid.best_params_['gamma']\n",
    "\n",
    "    C_list3 = np.arange(b2 - 0.1, b2 + 0.1, 0.01)\n",
    "    gamma_list3 = np.arange(g2 - 0.1, g2 + 0.1, 0.01)\n",
    "\n",
    "    grid = GridSearchCV(SVR(kernel='rbf'), param_grid={\"C\": C_list3, \"gamma\": gamma_list3}, cv=4, scoring='explained_variance')\n",
    "    grid.fit(X, y)\n",
    "    c = grid.best_params_['C']\n",
    "    gamma = grid.best_params_['gamma']\n",
    "\n",
    "    svr_rbf = SVR(kernel='rbf', C=c, gamma=gamma, epsilon=.1)\n",
    "    svm = svr_rbf.fit(X, y).predict(X)\n",
    "\n",
    "    inverseY = (scaler.inverse_transform(y.reshape(18, 1)).flatten()).tolist()\n",
    "    inverseSVM = (scaler.inverse_transform(svm.reshape(18, 1)).flatten()).tolist()\n",
    "\n",
    "    y = y.tolist()\n",
    "    svm = svm.tolist()\n",
    "\n",
    "    EVS = round(sm.explained_variance_score(y, svm), 2)\n",
    "    MSE = round(sm.mean_squared_error(y, svm), 2)\n",
    "\n",
    "    inverseSVM.append(cur_countyIndex)\n",
    "    inverseSVM.append(cur_IMFIndex)\n",
    "    inverseSVM.append(EVS)\n",
    "    inverseSVM.append(MSE)\n",
    "\n",
    "    dictionary[imf] = inverseSVM\n",
    "\n",
    "df = DataFrame(dictionary)\n",
    "df.to_csv(abs_path + 'SVR_IMFs_All.csv', index=False)\n",
    "\n",
    "print('SVR modeling success')\n",
    "\n",
    "# CODE 3: Aggregate IMF based on county\n",
    "\n",
    "EVI_SVR = pd.read_csv(abs_path + \"SVR_IMFs_All.csv\")\n",
    "SVR = EVI_SVR\n",
    "indexes = SVR.columns\n",
    "dictionary_sum = {}\n",
    "dictionary_res = {}\n",
    "county = '81'\n",
    "count = 0\n",
    "\n",
    "cur_sum = np.zeros((1, 18)).flatten()\n",
    "pre_imf = np.zeros((1, 18)).flatten()\n",
    "\n",
    "size = len(indexes)\n",
    "\n",
    "i = 0\n",
    "for index in indexes:\n",
    "    i += 1\n",
    "    cur_list = SVR[index]\n",
    "    cur_imf = np.array(cur_list[:18])\n",
    "    cur_county = str(int(cur_list[18]))\n",
    "    cur_i = int(cur_list[19])\n",
    "\n",
    "    if county == cur_county:\n",
    "        cur_sum = cur_sum + cur_imf\n",
    "        count += 1\n",
    "\n",
    "        if count >= 3:\n",
    "            pre_imf = cur_imf\n",
    "\n",
    "        if i == size:\n",
    "            dictionary_sum[county] = cur_sum\n",
    "            dictionary_res[county] = cur_imf\n",
    "\n",
    "    else:\n",
    "        dictionary_sum[county] = cur_sum\n",
    "        dictionary_res[county] = pre_imf\n",
    "\n",
    "        count = 1\n",
    "        cur_sum = cur_imf\n",
    "        county = cur_county\n",
    "    pre_i = cur_i\n",
    "    \n",
    "CID = ['81', '82', '83', '84', '85', '86', '87', '137', '138', '139', '144',\n",
    "       '366', '367', '368', '369', '370', '371', '372', '373', '374', '376', '496', '497',\n",
    "       '498', '499', '500', '501', '502', '503', '866', '867', '868', '870', '871', '872',\n",
    "       '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886',\n",
    "       '887', '2039', '2040', '2041', '2042', '2043', '2044', '2045', '2046', '2112',\n",
    "       '2115', '2116', '2117', '2118', '2119', '2120', '2121', '2122', '2123', '2124',\n",
    "       '2125']\n",
    "\n",
    "\n",
    "savePath1 = abs_path + \"SVR_All_IMFs_Agg.xlsx\"\n",
    "writer1 = pd.ExcelWriter(savePath1)\n",
    "df1 = DataFrame(dictionary_sum)\n",
    "df1.to_excel(writer1, 'Sheet1')\n",
    "writer1.close()\n",
    "print('SVR smoothed aggregated success')\n",
    "\n",
    "savePath2 = abs_path + 'SVR_All_IMFs_Res.xlsx'\n",
    "writer2 = pd.ExcelWriter(savePath2)\n",
    "df2 = DataFrame(dictionary_res)\n",
    "df2.to_excel(writer2, 'Sheet1')\n",
    "writer2.close()\n",
    "print('Final SVR smoothed residual success')\n",
    "\n",
    "# Save all output files in one Excel file with three tabs\n",
    "with pd.ExcelWriter(abs_path + 'Combined_Output.xlsx') as writer:\n",
    "    df3.to_excel(writer, sheet_name='All_EMD_Residuals', index=False)\n",
    "    df1.to_excel(writer, sheet_name='SVR_All_IMFs_Agg', index=False)\n",
    "    df2.to_excel(writer, sheet_name='SVR_All_IMFs_Res', index=False)\n",
    "\n",
    "print('All data output now created in one file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0724e2-a4a1-4ae3-aab1-b79e6e3300c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db11b4-34c8-472c-99ac-d35f0bb8d6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
